{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a71559d",
   "metadata": {},
   "source": [
    "**Requirements**\n",
    "\n",
    "1. Using sklearn library, perform classifications on the Iris dataset.\n",
    "\n",
    "2. Break the sample into 70% for training, and 30% for validation datasets. \n",
    "\n",
    "3. Using standard functions, compute the F1-score and accuracy of the model for both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a7e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#importing necessary modules\n",
    "\n",
    "\n",
    "#in this lab we will use K nearest neighbor classification to find the three nearest\n",
    "#neighbors and predict the class of 3/10 of our data set (VALIDATION SET)\n",
    "#using 7/10 of the data as training set\n",
    "print (\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938257f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width     plant_class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "[5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0, 7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9]\n",
      "<class 'list'>\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "#we want to read iris.data into a pandas dataframe\n",
    "#iris.data has no header columns so we create a list of column names\n",
    "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"plant_class\"]\n",
    "data = pd.read_csv(\"../data/iris.data\", delimiter=\",\", names=columns)\n",
    "\n",
    "#separate each \"series\" (column) of the dataframe into its own list\n",
    "sepal_length = data[\"sepal_length\"].tolist()\n",
    "sepal_width = data[\"sepal_width\"].tolist()\n",
    "petal_length = data[\"petal_length\"].tolist()\n",
    "petal_width = data[\"petal_width\"].tolist()\n",
    "plant_class = data[\"plant_class\"].tolist()\n",
    "\n",
    "#prints the data frame\n",
    "print(data)\n",
    "#prints the sepal_length column\n",
    "print(sepal_length)\n",
    "#confirm sepal_length is a list\n",
    "print(type(sepal_length))\n",
    "#prints length of our list (150)\n",
    "print(len(sepal_length))\n",
    "\n",
    "#at this point we have labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length encoded [ 8  6  4  3  7 11  3  7  1  6 11  5  5  0 15 14 11  8 14  8 11  8  3  8\n",
      "  5  7  7  9  9  4  5 11  9 12  6  7 12  6  1  8  7  2  1  7  8  5  8  3\n",
      " 10  7 27 21 26 12 22 14 20  6 23  9  7 16 17 18 13 24 13 15 19 13 16 18\n",
      " 20 18 21 23 25 24 17 14 12 12 15 17 11 17 24 20 13 12 12 18 15  7 13 14\n",
      " 14 19  8 14 20 15 28 20 22 32  6 30 24 29 22 21 25 14 15 21 22 33 33 17\n",
      " 26 13 33 20 24 29 19 18 21 29 31 34 21 20 18 33 20 21 17 26 24 26 15 25\n",
      " 24 24 20 22 19 16]\n",
      "sepal width encoded [14  9 11 10 15 18 13 13  8 10 16 13  9  9 19 22 18 14 17 17 13 16 15 12\n",
      " 13  9 13 14 13 11 10 13 20 21 10 11 14 10  9 13 14  2 11 14 17  9 17 11\n",
      " 16 12 11 11 10  2  7  7 12  3  8  6  0  9  1  8  8 10  9  6  1  4 11  7\n",
      "  4  7  8  9  7  9  8  5  3  3  6  6  9 13 10  2  9  4  5  9  5  2  6  9\n",
      "  8  8  4  7 12  6  9  8  9  9  4  8  4 15 11  6  9  4  7 11  9 17  5  1\n",
      " 11  7  7  6 12 11  7  9  7  9  7 17  7  7  5  9 13 10  9 10 10 10  6 11\n",
      " 12  9  4  9 13  9]\n",
      "petal length encoded [ 4  4  3  5  4  7  4  5  4  5  5  6  4  1  2  5  3  4  7  5  7  5  0  7\n",
      "  8  6  6  5  4  6  6  5  5  4  5  2  3  5  3  5  3  3  3  6  8  4  6  4\n",
      "  5  4 23 21 25 16 22 21 23 10 22 15 11 18 16 23 12 20 21 17 21 15 24 16\n",
      " 25 23 19 20 24 26 21 11 14 13 15 27 21 21 23 20 17 16 20 22 16 10 18 18\n",
      " 18 19  9 17 36 27 35 32 34 40 21 38 34 37 27 29 31 26 27 29 31 41 42 26\n",
      " 33 25 41 25 33 36 24 25 32 34 37 39 32 27 32 37 32 31 24 30 32 27 27 35\n",
      " 33 28 26 28 30 27]\n",
      "petal width encoded [ 1  1  1  1  1  3  2  1  1  0  1  1  0  0  1  3  3  2  2  2  1  3  1  4\n",
      "  1  1  3  1  1  1  1  3  0  1  0  1  1  0  1  1  2  2  1  5  3  2  1  1\n",
      "  1  1 10 11 11  9 11  9 12  6  9 10  6 11  6 10  9 10 11  6 11  7 14  9\n",
      " 11  8  9 10 10 13 11  6  7  6  8 12 11 12 11  9  9  9  8 10  8  6  9  8\n",
      "  9  9  7  9 21 15 17 14 18 17 13 14 14 21 16 15 17 16 20 19 14 18 19 11\n",
      " 19 16 16 14 17 14 14 14 17 12 15 16 18 11 10 19 20 14 14 17 20 19 15 19\n",
      " 21 19 15 16 19 14]\n",
      "label (plant class) encoded [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#we want to convert our labeled data to encoded data\n",
    "#use fit_transform function in our label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "sepal_length_encoded = le.fit_transform(sepal_length)\n",
    "print('sepal length encoded', sepal_length_encoded)\n",
    "sepal_width_encoded = le.fit_transform(sepal_width)\n",
    "print('sepal width encoded', sepal_width_encoded)\n",
    "petal_length_encoded = le.fit_transform(petal_length)\n",
    "print('petal length encoded', petal_length_encoded)\n",
    "petal_width_encoded = le.fit_transform(petal_width)\n",
    "print('petal width encoded', petal_width_encoded)\n",
    "#the plant class will be our label (this is what we are predicting given the training set)\n",
    "label = le.fit_transform(plant_class)\n",
    "print('label (plant class) encoded', label)\n",
    "\n",
    "#at this point the data is encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6e45ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features [(8, 14, 4, 1), (6, 9, 4, 1), (4, 11, 3, 1), (3, 10, 5, 1), (7, 15, 4, 1), (11, 18, 7, 3), (3, 13, 4, 2), (7, 13, 5, 1), (1, 8, 4, 1), (6, 10, 5, 0), (11, 16, 5, 1), (5, 13, 6, 1), (5, 9, 4, 0), (0, 9, 1, 0), (15, 19, 2, 1), (14, 22, 5, 3), (11, 18, 3, 3), (8, 14, 4, 2), (14, 17, 7, 2), (8, 17, 5, 2), (11, 13, 7, 1), (8, 16, 5, 3), (3, 15, 0, 1), (8, 12, 7, 4), (5, 13, 8, 1), (7, 9, 6, 1), (7, 13, 6, 3), (9, 14, 5, 1), (9, 13, 4, 1), (4, 11, 6, 1), (5, 10, 6, 1), (11, 13, 5, 3), (9, 20, 5, 0), (12, 21, 4, 1), (6, 10, 5, 0), (7, 11, 2, 1), (12, 14, 3, 1), (6, 10, 5, 0), (1, 9, 3, 1), (8, 13, 5, 1), (7, 14, 3, 2), (2, 2, 3, 2), (1, 11, 3, 1), (7, 14, 6, 5), (8, 17, 8, 3), (5, 9, 4, 2), (8, 17, 6, 1), (3, 11, 4, 1), (10, 16, 5, 1), (7, 12, 4, 1), (27, 11, 23, 10), (21, 11, 21, 11), (26, 10, 25, 11), (12, 2, 16, 9), (22, 7, 22, 11), (14, 7, 21, 9), (20, 12, 23, 12), (6, 3, 10, 6), (23, 8, 22, 9), (9, 6, 15, 10), (7, 0, 11, 6), (16, 9, 18, 11), (17, 1, 16, 6), (18, 8, 23, 10), (13, 8, 12, 9), (24, 10, 20, 10), (13, 9, 21, 11), (15, 6, 17, 6), (19, 1, 21, 11), (13, 4, 15, 7), (16, 11, 24, 14), (18, 7, 16, 9), (20, 4, 25, 11), (18, 7, 23, 8), (21, 8, 19, 9), (23, 9, 20, 10), (25, 7, 24, 10), (24, 9, 26, 13), (17, 8, 21, 11), (14, 5, 11, 6), (12, 3, 14, 7), (12, 3, 13, 6), (15, 6, 15, 8), (17, 6, 27, 12), (11, 9, 21, 11), (17, 13, 21, 12), (24, 10, 23, 11), (20, 2, 20, 9), (13, 9, 17, 9), (12, 4, 16, 9), (12, 5, 20, 8), (18, 9, 22, 10), (15, 5, 16, 8), (7, 2, 10, 6), (13, 6, 18, 9), (14, 9, 18, 8), (14, 8, 18, 9), (19, 8, 19, 9), (8, 4, 9, 7), (14, 7, 17, 9), (20, 12, 36, 21), (15, 6, 27, 15), (28, 9, 35, 17), (20, 8, 32, 14), (22, 9, 34, 18), (32, 9, 40, 17), (6, 4, 21, 13), (30, 8, 38, 14), (24, 4, 34, 14), (29, 15, 37, 21), (22, 11, 27, 16), (21, 6, 29, 15), (25, 9, 31, 17), (14, 4, 26, 16), (15, 7, 27, 20), (21, 11, 29, 19), (22, 9, 31, 14), (33, 17, 41, 18), (33, 5, 42, 19), (17, 1, 26, 11), (26, 11, 33, 19), (13, 7, 25, 16), (33, 7, 41, 16), (20, 6, 25, 14), (24, 12, 33, 17), (29, 11, 36, 14), (19, 7, 24, 14), (18, 9, 25, 14), (21, 7, 32, 17), (29, 9, 34, 12), (31, 7, 37, 15), (34, 17, 39, 16), (21, 7, 32, 18), (20, 7, 27, 11), (18, 5, 32, 10), (33, 9, 37, 19), (20, 13, 32, 20), (21, 10, 31, 14), (17, 9, 24, 14), (26, 10, 30, 17), (24, 10, 32, 20), (26, 10, 27, 19), (15, 6, 27, 15), (25, 11, 35, 19), (24, 12, 33, 21), (24, 9, 28, 19), (20, 4, 26, 15), (22, 9, 28, 16), (19, 13, 30, 19), (16, 9, 27, 14)]\n"
     ]
    }
   ],
   "source": [
    "#combine our features into one list\n",
    "features = list(zip(sepal_length_encoded, sepal_width_encoded, petal_length_encoded, petal_width_encoded))\n",
    "print('Features', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bbe3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split our feature list into training and validation\n",
    "#we will have 70:30 ratio; in this case 105 data points in training, 45 in validation\n",
    "#we will use data collected in training to predict the class of the validation samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a0933a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the classifier\n",
    "#k=3 thus we look for the three nearest neighbors\n",
    "#using the Minkowski distance metrics for proximity\n",
    "#majority vote will determine our class prediction\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "#train the classifier\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e9c5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test set [0 1 2 1 2 2 2 0 1 0 0 1 1 1 1 2 2 1 1 0 0 1 1 0 0 0 2 0 2 2 2 1 2 1 1 1 2\n",
      " 1 0 2 2 0 2 1 1]\n",
      "Actual data from the test set [0 1 2 1 2 2 1 0 1 0 0 1 1 1 1 2 2 1 1 0 0 1 1 0 0 0 2 0 2 2 2 1 2 1 1 1 2\n",
      " 1 0 2 2 0 2 1 1]\n",
      "Predicting the train set [1 2 1 1 0 1 0 1 2 0 0 2 1 2 0 2 0 0 2 0 1 2 0 1 0 1 2 2 2 0 1 1 0 0 0 0 1\n",
      " 0 1 2 2 0 0 2 2 2 0 1 0 2 1 2 0 0 1 2 2 1 2 1 2 1 1 2 1 1 2 2 1 2 2 2 2 2\n",
      " 0 1 2 2 0 0 1 2 0 0 0 0 2 1 0 0 2 1 0 1 1 0 2 0 0 0 2 0 2 1 0]\n",
      "Actual data from the train set [1 2 2 1 0 1 0 1 2 0 0 1 1 2 0 2 0 0 2 0 1 2 0 1 0 1 2 2 2 0 1 1 0 0 0 0 1\n",
      " 0 1 2 2 0 0 2 1 2 0 1 0 2 1 2 0 0 1 2 2 1 2 1 2 1 1 2 1 1 2 2 1 2 2 2 2 2\n",
      " 0 1 2 2 0 0 1 2 0 0 0 0 2 1 0 0 2 1 0 1 1 0 2 0 0 0 2 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "#predicting our validation set using the trained classifier\n",
    "y_validation = model.predict(X_test)\n",
    "print('Predicting the test set', y_validation)\n",
    "print('Actual data from the test set', y_test)\n",
    "\n",
    "#predicting values of the training set using the trained classifier\n",
    "y_training = model.predict(X_train)\n",
    "print('Predicting the train set', y_training)\n",
    "print('Actual data from the train set', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6bd2874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction model on the validation set 0.9777777777777777\n",
      "44 out of 45 samples classified correctly\n",
      "Accuracy of predicion model on the training set 0.9714285714285714\n",
      "102 out of 105 samples classified correctly\n"
     ]
    }
   ],
   "source": [
    "#evaluating accuracy of prediction on validation model\n",
    "accuracy = accuracy_score(y_test, y_validation)\n",
    "print('Accuracy of prediction model on the validation set', accuracy)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_validation, normalize=False)\n",
    "print(accuracy, 'out of 45 samples classified correctly')\n",
    "\n",
    "#evaluating accuracy of prediction on training set\n",
    "accuracy = accuracy_score(y_train, y_training)\n",
    "print('Accuracy of predicion model on the training set', accuracy)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_training, normalize=False)\n",
    "print(accuracy, 'out of 105 samples classified correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d62622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on validation set 0.9778606192399296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#evaluating f1_score of our prediction on the validation set\n",
    "f1_score = f1_score(y_test, y_validation, average='weighted')\n",
    "print('f1 score of prediction on validation set', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e8f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of prediction on training set 0.9713900741073435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#evaluating f1_score of our prediction on the training set\n",
    "f1_score = f1_score(y_train, y_training, average='weighted')\n",
    "print('f1 score of prediction on training set', f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
